{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing import *\n",
    "\n",
    "train_data, OUT_DIM = load_create_ellipticpp(timestep=(1,32))\n",
    "test_data, OUT_DIM = load_create_ellipticpp(timestep=(33,42))\n",
    "\n",
    "# loader = split_into_batches(data, num_batches=batch_size, num_hops=2, num_neighbours=100)\n",
    "# num_features = next(iter(loader)).x.shape[-1]\n",
    "# data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe remvoe mask and cosnider temporal split for elliptic++\n",
    "# dataloader (from pt) - implement sampler here -> neighourloader\n",
    "# summary stats on avg degree of a node when considering ([-1,-1] neighbourhoods)\n",
    "# graphsage/gat with full neighbourhood, 75%/50%/25% reduction in neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import Sampler\n",
    "# from torch_geometric.loader import DataLoader\n",
    "# from typing import Iterator, Iterable, List\n",
    "\n",
    "# class customGraphSampler(Sampler[List[int]]):\n",
    "#     def __init__(self, data: Iterable, batch_size: int=32, positive_label: int=1, negative_label: int=0) -> None:\n",
    "#         self.data = data\n",
    "#         self.batch_size = batch_size\n",
    "#         self.positive_label = positive_label\n",
    "#         self.negative_label = negative_label\n",
    "\n",
    "#     # number of batches\n",
    "#     # @TODO: recompute based on labels\n",
    "#     def __len__(self) -> int:\n",
    "#         return (len(self.data.x) + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "#     def _is_half_batch_size(self, counter_sample) -> int:\n",
    "#         return counter_sample >= self.batch_size // 2\n",
    "\n",
    "#     def __iter__(self) -> Iterator[int]:\n",
    "#         batch = []\n",
    "#         # torch where y == 0, y == 1 -> select first batch_size idx `y == 0` and batch_size - selection_size `y == 1`\n",
    "        \n",
    "#         # ****@TODO: iterate over the entire dataset and add to single list? -- and discard non relevant batches\n",
    "#         ### get all neighbours\n",
    "#         # @TODO: iterate over the entire dataset but keep some other batches as well\n",
    "#         # @TODO: accumulate positive and negative in separate lists and then combine?\n",
    "#         # @TODO: sample from two lists and add indices\n",
    "\n",
    "#         # @TODO: shuffle indices?\n",
    "#         self.sizes = 2\n",
    "\n",
    "#         # [1,0,1,0,2_]\n",
    "#         # pos = 2\n",
    "#         # neg = 2\n",
    "#         # idx = 4 -> idx+1 = 5\n",
    "#         # len = 5\n",
    "\n",
    "#         counter_positive_label = 0\n",
    "#         counter_negative_label = 0\n",
    "#         for idx, label in enumerate(self.data.y):\n",
    "#             if label == self.positive_label and not self._is_half_batch_size(counter_positive_label) and idx in self.data.edge_index[0]:\n",
    "#                 batch += [idx]\n",
    "#                 counter_positive_label += 1\n",
    "#             elif label == self.negative_label and not self._is_half_batch_size(counter_negative_label) and idx in self.data.edge_index[0]:\n",
    "#                 batch += [idx]\n",
    "#                 counter_negative_label += 1\n",
    "\n",
    "#             if (len(batch) == self.batch_size):\n",
    "#                 # print(batch)\n",
    "#                 # yield self.data.subgraph(torch.as_tensor(batch))\n",
    "#                 yield batch\n",
    "#                 batch = []\n",
    "#                 counter_positive_label = 0\n",
    "#                 counter_negative_label = 0\n",
    "\n",
    "# # get node idx (Y) -> make batch (Y) -> get ALL neibghours of idx (in n hops)\n",
    "# # separate graph into subgraphs (where each subgraph = 64 nodes + neighbours) -> make batches ...\n",
    "\n",
    "# # s = customGraphSampler(d, batch_size=6, positive_label=0, negative_label=1) # generate indices to form a batch\n",
    "# # da = DataLoader(dataset=d.x, sampler=s, batch_size=5) # go over the entire dataset (here, list of node values) and create a batch from the sampled indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Sampler\n",
    "from torch_geometric.loader import DataLoader\n",
    "from typing import Iterator, Iterable, List\n",
    "\n",
    "class customGraphSampler(Sampler[List[int]]):\n",
    "    def __init__(self, data: Iterable, batch_size: int=32, positive_label: int=1, negative_label: int=0) -> None:\n",
    "        torch.manual_seed(42)\n",
    "\n",
    "        self.data = data\n",
    "        self.batch_size = batch_size\n",
    "        self.positive_label = positive_label\n",
    "        self.negative_label = negative_label\n",
    "\n",
    "        self.y_positive_idx = torch.where(self.data.y == positive_label, 1, 0).nonzero().squeeze()\n",
    "        self.y_positive_idx = self.y_positive_idx[torch.randperm(self.y_positive_idx.size()[0])]\n",
    "\n",
    "        self.y_negative_idx = torch.where(self.data.y == negative_label, 1, 0).nonzero().squeeze()\n",
    "        self.y_negative_idx = self.y_negative_idx[torch.randperm(self.y_negative_idx.size()[0])]\n",
    "\n",
    "    # number of batches\n",
    "    # @TODO: recompute based on labels\n",
    "    def __len__(self) -> int:\n",
    "        return (len(self.data.x) + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "    def _is_half_batch_size(self, counter_sample) -> int:\n",
    "        return counter_sample >= self.batch_size // 2\n",
    "\n",
    "    def __iter__(self) -> Iterator[int]:\n",
    "        batch = []\n",
    "        # torch where y == 0, y == 1 -> select first batch_size idx `y == 0` and batch_size - selection_size `y == 1`\n",
    "        \n",
    "        # ****@TODO: iterate over the entire dataset and add to single list? -- and discard non relevant batches\n",
    "        ### get all neighbours\n",
    "        # @TODO: iterate over the entire dataset but keep some other batches as well\n",
    "        # @TODO: accumulate positive and negative in separate lists and then combine?\n",
    "        # @TODO: sample from two lists and add indices\n",
    "\n",
    "        # @TODO: shuffle indices?\n",
    "\n",
    "        print(self.y_positive_idx.shape)\n",
    "        print(self.y_negative_idx.shape)\n",
    "\n",
    "        aux_y_positive_idx = self.y_positive_idx\n",
    "        aux_y_negative_idx = self.y_negative_idx\n",
    "\n",
    "        half_batch_size = self.batch_size // 2\n",
    "\n",
    "        while aux_y_positive_idx.shape[0] >= half_batch_size and aux_y_negative_idx.shape[0] >= half_batch_size:\n",
    "            positive_labels = aux_y_positive_idx[:half_batch_size]\n",
    "            aux_y_positive_idx = aux_y_positive_idx[half_batch_size:]\n",
    "\n",
    "            negative_labels = aux_y_negative_idx[:half_batch_size]\n",
    "            aux_y_negative_idx = aux_y_negative_idx[half_batch_size:]\n",
    "\n",
    "            batch = torch.concat([positive_labels, negative_labels], dim=-1)\n",
    "\n",
    "            yield batch\n",
    "\n",
    "# add hops to get neighbours of neighbours\n",
    "# also include all selected nodes\n",
    "def select_nodes_from_central(data: Data, nodes: torch.Tensor):\n",
    "    edge_mask = [data.edge_index[:,torch.where(data.edge_index == node, 1, 0)[0].nonzero().squeeze(-1)] for node in nodes]\n",
    "    edge_index = torch.concat(edge_mask, dim=1)\n",
    "\n",
    "    print(edge_index)\n",
    "\n",
    "    node_new_idx_map = {old_idx: new_idx for new_idx, old_idx in enumerate(edge_index.unique().tolist())}\n",
    "    for old_idx, new_idx in node_new_idx_map.items():\n",
    "        edge_index[edge_index == old_idx] = new_idx\n",
    "\n",
    "    all_old_nodes_idx = list(node_new_idx_map.keys())\n",
    "    return edge_index, all_old_nodes_idx\n",
    "\n",
    "def split(data: Data, sampler):\n",
    "    batch_graph = []\n",
    "    for sample in sampler:\n",
    "        edge_index, old_idx = select_nodes_from_central(data, sample)\n",
    "        batch_graph += [\n",
    "            Data(x=data.x[old_idx,:],\n",
    "                 y=data.y[old_idx],\n",
    "                 edge_index=edge_index,\n",
    "                 train_mask = data.y[sample])\n",
    "        ]\n",
    "        print(sample.shape[0])\n",
    "        print(sum([s.item() in old_idx for s in sample])/sample.shape[0])\n",
    "        print(sample)\n",
    "        print(old_idx)\n",
    "        break\n",
    "\n",
    "    return batch_graph\n",
    "\n",
    "# get node idx (Y) -> make batch (Y) -> get ALL neibghours of idx (in n hops)\n",
    "# separate graph into subgraphs (where each subgraph = 64 nodes + neighbours) -> make batches ...\n",
    "\n",
    "# s = customGraphSampler(d, batch_size=6, positive_label=0, negative_label=1) # generate indices to form a batch\n",
    "# da = DataLoader(dataset=d.x, sampler=s, batch_size=5) # go over the entire dataset (here, list of node values) and create a batch from the sampled indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18456])\n",
      "torch.Size([212521])\n",
      "tensor([[483418, 483418, 398215, 398215],\n",
      "        [492824, 509093, 191336,   6430]], device='cuda:0')\n",
      "4\n",
      "0.5\n",
      "tensor([483418, 459271, 258212, 398215], device='cuda:0')\n",
      "[6430, 191336, 398215, 483418, 492824, 509093]\n"
     ]
    }
   ],
   "source": [
    "batch_sampler = customGraphSampler(train_data, batch_size=5, positive_label=0, negative_label=1) # generate indices to form a batch\n",
    "subgraphs = split(train_data, batch_sampler)\n",
    "train_data_batches = DataLoader(subgraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7346])\n",
      "torch.Size([71363])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], device='cuda:0')\n",
      "tensor(43, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "batch_sampler = customGraphSampler(test_data, batch_size=64, positive_label=0, negative_label=1) # generate indices to form a batch\n",
    "subgraphs = split(test_data, batch_sampler)\n",
    "test_data_batches = DataLoader(subgraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2], device='cuda:0')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = next(iter(train_data_batches))\n",
    "s.y[s.train_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove timestep attribute !!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "\n",
    "# sample = next(iter(loader))\n",
    "# (sample.y.tolist())\n",
    "\n",
    "# Counter(sample.y.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.datasets import elliptic\n",
    "\n",
    "# da = elliptic.EllipticBitcoinDataset(\"./\").data.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader = split_into_batches(da, num_batches=100000, num_neighbours=100, num_hops=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imbalanced dataset -> try to sample in a batch 64 central nodes - 32 class 0, 32 class 1\n",
    "# use 2 neighbourloaders -> one for central node with custom sampling, one with random for neighbours (using node idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, **layer_paras):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_layers = layer_paras.pop(\"num_layers\",1)\n",
    "        self.hidden_dim = layer_paras.pop(\"hidden_channels\")\n",
    "        self.cached = layer_paras.pop(\"cached\", True)\n",
    "\n",
    "        self.dropout = layer_paras.pop(\"dropout\", 0.0)\n",
    "\n",
    "        self.conv_layers = []\n",
    "\n",
    "        self.conv_layers += [\n",
    "            SAGEConv(in_dim, self.hidden_dim) # input layer; cached=True => for transductive learning\n",
    "        ]\n",
    "        for _ in range(self.num_layers-2):\n",
    "            self.conv_layers += [\n",
    "                SAGEConv(self.hidden_dim, self.hidden_dim)\n",
    "            ]\n",
    "        self.conv_layers += [\n",
    "            SAGEConv(self.hidden_dim, out_dim) # output layer; cached=True => for transductive learning\n",
    "        ]\n",
    "\n",
    "        self.conv_layers = torch.nn.ParameterList(self.conv_layers)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for conv in self.conv_layers[:-1]:\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, training=self.training, p=self.dropout)\n",
    "        x = self.conv_layers[-1](x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SAGE(\n",
       "  (conv_layers): ParameterList(\n",
       "      (0): Object of type: SAGEConv\n",
       "      (1): Object of type: SAGEConv\n",
       "      (2): Object of type: SAGEConv\n",
       "    (0): SAGEConv(55, 55, aggr=mean)\n",
       "    (1): SAGEConv(55, 55, aggr=mean)\n",
       "    (2): SAGEConv(55, 2, aggr=mean)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paras = {\n",
    "    'lr':0.01,\n",
    "    'num_layers':3,\n",
    "    'hidden_channels':55,\n",
    "    'dropout':0.4,\n",
    "    'batchnorm': False,\n",
    "    'l2':5e-7,\n",
    "    'cached': True,\n",
    "}\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SAGE(in_dim=55, out_dim=2, **paras).to(DEVICE)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [0,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [1,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [3,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [4,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [6,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [7,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [8,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [9,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [10,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [11,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [12,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [13,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [14,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [15,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [16,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [17,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [18,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [19,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [20,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [21,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [22,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [23,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [24,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [25,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [26,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [27,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [28,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [29,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [30,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:250: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [31,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[74]\u001b[39m\u001b[32m, line 40\u001b[39m\n\u001b[32m     36\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_all, loss_valid_all\n\u001b[32m     38\u001b[39m optimizer = torch.optim.Adam(model.parameters(), lr=paras[\u001b[33m\"\u001b[39m\u001b[33mlr\u001b[39m\u001b[33m\"\u001b[39m], weight_decay=paras[\u001b[33m\"\u001b[39m\u001b[33ml2\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m loss_all, loss_valid_all = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_num\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[74]\u001b[39m\u001b[32m, line 16\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(batches, model, optimizer, epoch_num)\u001b[39m\n\u001b[32m     13\u001b[39m out = model(batch.x, batch.edge_index)\n\u001b[32m     15\u001b[39m loss = F.cross_entropy(out[batch.train_mask], batch.y[batch.train_mask])\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m running_loss += \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m optimizer.zero_grad()\n\u001b[32m     19\u001b[39m loss.backward()\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(batches, model, optimizer, epoch_num=1):\n",
    "    loss_all = []\n",
    "    loss_valid_all = []\n",
    "\n",
    "    model.train()\n",
    "    iterator = tqdm(range(epoch_num), desc=\"\")\n",
    "    for epoch in iterator:\n",
    "        running_loss = 0\n",
    "        valid_loss = 0\n",
    "        for idx, batch in enumerate(batches):\n",
    "            out = model(batch.x, batch.edge_index)\n",
    "\n",
    "            loss = F.cross_entropy(out[batch.train_mask], batch.y[batch.train_mask])\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            iterator.set_description(f\"Epoch: {epoch+1}/{epoch_num}; Batch: {idx+1}/{len(subgraphs)}; Loss: {running_loss/(idx+1):0.4f}\")\n",
    "\n",
    "        # loss_valid = F.cross_entropy(out[batch.val_mask], batch.y[batch.val_mask])\n",
    "        # running_valid_loss += loss_valid.item()    \n",
    "        # iterator.set_description(f\"Epoch: {epoch+1}/{epoch_num}; Batch: {idx+1}/{data.x.shape[0]//batch_size}; Loss: {running_loss/(idx+1):0.4f}\")\n",
    "        # @TODO: add validation round to monitor performance\n",
    "        # loss_all += [running_loss/(data.x.shape[0]//batch_size)]\n",
    "        # loss_valid_all += [running_valid_loss/(data.x.shape[0]//batch_size)]\n",
    "\n",
    "        loss_all += [running_loss/(idx+1)]\n",
    "        loss_valid_all += [valid_loss]\n",
    "\n",
    "        iterator.set_description(f\"Epoch: {epoch+1}/{epoch_num}; Batch: {idx}; Loss={loss_all[-1]:.4f}; Loss-Validation={loss_valid_all[-1]:.4f}\")\n",
    "\n",
    "    return loss_all, loss_valid_all\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=paras[\"lr\"], weight_decay=paras[\"l2\"])\n",
    "\n",
    "loss_all, loss_valid_all = train(train_data_batches, model, optimizer, epoch_num=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x759fe69aa300>]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAGdCAYAAAAMm0nCAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAOAhJREFUeJzt3Xt0VOW9//HP5DITAslwTSaRCIgSbglQVE68IAoSQrD11FOrolBLRXvQVuPPImu1iNojVFpbj+XYuk6RnsoptKeV1qBAuEYlKAZDQtAICAYkk3CdSQLkun9/hIyMBMiEmczsyfu11l6L2fuZzPfpblY+znc/e1sMwzAEAABgIhHBLgAAAMBXBBgAAGA6BBgAAGA6BBgAAGA6BBgAAGA6BBgAAGA6BBgAAGA6BBgAAGA6UcEuIFCam5t1+PBhxcXFyWKxBLscAADQDoZhqLq6WsnJyYqIuPD3LGEbYA4fPqyUlJRglwEAADrg4MGD6t+//wWPh22AiYuLk9TyP0B8fHyQqwEAAO3hdruVkpLi+Tt+IWEbYFrbRvHx8QQYAABM5lKXf3ARLwAAMB0CDAAAMB0CDAAAMB0CDAAAMB0CDAAAMB0CDAAAMB0CDAAAMB0CDAAAMB0CDAAAMB0CDAAAMB0CDAAAMB0CDAAAMB0CjI/WlTo15393aE9ldbBLAQCgyyLA+Gjl9oNaXVyh3OKKYJcCAECXRYDxUXZ6kiRpdQkBBgCAYCHA+GjS8ERZIyO0t6pGn9FGAgAgKAgwPoqPidb4If0kiTYSAABBQoDpgOx0hyRpdfFhGYYR5GoAAOh6CDAdMGlYoqxREdp3pFZltJEAAOh0BJgOiIuJ1i1n20iraSMBANDpCDAdNK11NVJxBW0kAAA6GQGmgyaebSN9frRWn1TQRgIAoDMRYDqohy1Kt6aebSOVHA5yNQAAdC0EmMuQnZ4siTYSAACdjQBzGSYOTZAtKkIHjp3S7gp3sMsBAKDLIMBchu62KN02NEESq5EAAOhMBJjLNDXtq2cj0UYCAKBzEGAu021DExQTHaEvjp1S6WHaSAAAdAYCzGU6t43Es5EAAOgcBBg/yE47uxqphGcjAQDQGQgwfnDr0H7qFh2pg8dPq+RLV7DLAQAg7BFg/CDWGqXbhrEaCQCAzuJzgMnPz9cdd9yh5ORkWSwWrVq1yuu4xWJpc1u8eLFnzMCBA887vmjRIq+fU1xcrJtvvlkxMTFKSUnRiy++2LEZdpJpZ1cj5XJTOwAAAs7nAFNbW6tRo0ZpyZIlbR6vqKjw2pYuXSqLxaK77rrLa9xzzz3nNe6xxx7zHHO73Zo8ebIGDBigwsJCLV68WAsWLNBrr73ma7mdZkJqgmKtkfry5GkVH6KNBABAIEX5+oasrCxlZWVd8LjD4fB6/Y9//EO33nqrrrrqKq/9cXFx541ttXz5ctXX12vp0qWyWq0aMWKEioqK9NJLL2n27Nm+ltwpulkjNXFYot7aeVirSyo0KqVnsEsCACBsBfQamMrKSq1evVqzZs0679iiRYvUp08fjRkzRosXL1ZjY6PnWEFBgcaPHy+r1erZl5mZqbKyMp04caLNz6qrq5Pb7fbaOlt2Wksg49lIAAAEVkADzB//+EfFxcXp29/+ttf+H/3oR1qxYoU2bdqkhx9+WC+88IJ+8pOfeI47nU4lJiZ6vaf1tdPpbPOzFi5cKLvd7tlSUlL8PJtLO7eNVHTwZKd/PgAAXUVAA8zSpUs1ffp0xcTEeO3PycnRhAkTlJ6erkceeUS/+tWv9Morr6iurq7DnzVv3jy5XC7PdvDgwcst32cx0ZGaNKwlaLEaCQCAwAlYgHn33XdVVlamH/zgB5ccO27cODU2NurAgQOSWq6jqays9BrT+vpC183YbDbFx8d7bcGQnd6yGuntkgo1N9NGAgAgEAIWYP7whz9o7NixGjVq1CXHFhUVKSIiQgkJLfdSycjIUH5+vhoaGjxj8vLylJqaql69egWqZL+4ZUg/dbdG6rDrjD6mjQQAQED4HGBqampUVFSkoqIiSdL+/ftVVFSk8vJyzxi3262//vWvbX77UlBQoN/85jfauXOnPv/8cy1fvlxPPPGE7r//fk84ue+++2S1WjVr1iyVlpZq5cqVevnll5WTk9PBaXaemOhI3T6cNhIAAIHkc4D56KOPNGbMGI0ZM0ZSy/UsY8aM0fz58z1jVqxYIcMwdO+99573fpvNphUrVuiWW27RiBEj9B//8R964oknvO7xYrfbtW7dOu3fv19jx47Vk08+qfnz54fsEuqvy05veTYSbSQAAALDYoTpel+32y273S6Xy9Xp18OcaWjSdT9fr+q6Rv3fIxm6dmDvTv18AADMqr1/v3kWUgB4tZFKaCMBAOBvBJgAmZrGaiQAAAKFABMgNw/pqzhblCrddSosb/vuwQAAoGMIMAFii4rU7SNYjQQAQCAQYAJo2jk3tWuijQQAgN8QYALopqv7KS4mSlXVdfrowPFglwMAQNggwASQNSpCmSPOPqGa1UgAAPgNASbAvno2kpM2EgAAfkKACbAbB/eVvVu0jtbU6cP9tJEAAPAHAkyAtbSRWlYjvU0bCQAAvyDAdILWZyO9s4vVSAAA+AMBphPcMLiPesZG62hNvT7YfyzY5QAAYHoEmE4QHRmhzOFnVyNxUzsAAC4bAaaTtK5GWrPLqcam5iBXAwCAuRFgOknG4D7qFRutY7X1+oDVSAAAXBYCTCeJjozQlJEtbaRc2kgAAFwWAkwnyk5rWY20ZlcFbSQAAC4DAaYT/ctVvdW7u1UnTjWo4HNWIwEA0FEEmE4UdU4biZvaAQDQcQSYTjYt7avVSA20kQAA6BACTCe7flBv9WltI+2jjQQAQEcQYDrZuW0kbmoHAEDHEGCCwHNTu1LaSAAAdAQBJgjGDeqjvj2scp1u0Pt7jwa7HAAATIcAEwSRERZljWz5FoY2EgAAviPABElrG2ltqVP1jbSRAADwBQEmSK4b2Fv94mxyn2mkjQQAgI8IMEESGWHRVJ6NBABAhxBggig7veXZSOt200YCAMAXBJggunZALyXE2VR9plHv7T0S7HIAADANAkwQRURYNPXsowVoIwEA0H4EmCBrXY2UV1qpusamIFcDAIA5EGCCbOyVvZQYb1N1XaPe/YzVSAAAtIfPASY/P1933HGHkpOTZbFYtGrVKq/j3/ve92SxWLy2KVOmeI05fvy4pk+frvj4ePXs2VOzZs1STU2N15ji4mLdfPPNiomJUUpKil588UXfZ2cC57aRVpfQRgIAoD18DjC1tbUaNWqUlixZcsExU6ZMUUVFhWf785//7HV8+vTpKi0tVV5ennJzc5Wfn6/Zs2d7jrvdbk2ePFkDBgxQYWGhFi9erAULFui1117ztVxTmNbaRtpdqTMNtJEAALiUKF/fkJWVpaysrIuOsdlscjgcbR775JNPtGbNGm3fvl3XXnutJOmVV17R1KlT9ctf/lLJyclavny56uvrtXTpUlmtVo0YMUJFRUV66aWXvIJOuBiT0ktJ9hhVuM4o/7Mjmjyi7f/tAABAi4BcA7N582YlJCQoNTVVP/zhD3Xs2DHPsYKCAvXs2dMTXiRp0qRJioiI0AcffOAZM378eFmtVs+YzMxMlZWV6cSJE4EoOahoIwEA4Bu/B5gpU6bof/7nf7Rhwwb94he/0JYtW5SVlaWmppbWiNPpVEJCgtd7oqKi1Lt3bzmdTs+YxMRErzGtr1vHfF1dXZ3cbrfXZiatq5HW00YCAOCSfG4hXco999zj+XdaWprS09M1ePBgbd68WRMnTvT3x3ksXLhQzz77bMB+fqCNSempZHuMDrvOaMtnR5RJGwkAgAsK+DLqq666Sn379tXevXslSQ6HQ1VVVV5jGhsbdfz4cc91Mw6HQ5WVlV5jWl9f6NqaefPmyeVyebaDBw/6eyoBZbGc00bipnYAAFxUwAPMoUOHdOzYMSUltfxxzsjI0MmTJ1VYWOgZs3HjRjU3N2vcuHGeMfn5+WpoaPCMycvLU2pqqnr16tXm59hsNsXHx3ttZuNpI31CGwkAgIvxOcDU1NSoqKhIRUVFkqT9+/erqKhI5eXlqqmp0VNPPaVt27bpwIED2rBhg771rW/p6quvVmZmpiRp2LBhmjJlih566CF9+OGHev/99/Xoo4/qnnvuUXJyy8MN77vvPlmtVs2aNUulpaVauXKlXn75ZeXk5Phv5iFodEpPXdGzm07VN2lzWdWl3wAAQBflc4D56KOPNGbMGI0ZM0aSlJOTozFjxmj+/PmKjIxUcXGxvvnNb2rIkCGaNWuWxo4dq3fffVc2m83zM5YvX66hQ4dq4sSJmjp1qm666Save7zY7XatW7dO+/fv19ixY/Xkk09q/vz5YbmE+lwWi8XzLQzPRgIA4MIshmEYwS4iENxut+x2u1wul6naSTsPntS3lryvbtGR2vGz29XNGhnskgAA6DTt/fvNs5BCTHp/u/r36qbTDU3aRBsJAIA2EWBCzLltJFYjAQDQNgJMCJqW1nIx88ZPq3SqvjHI1QAAEHoIMCFo5BXxurJ3bEsb6dMjwS4HAICQQ4AJQV43tSs5HORqAAAIPQSYEDXt7HUwGz+tUm0dbSQAAM5FgAlRI5LjNaBPrM40NGvjp6xGAgDgXASYEGWxWJTNs5EAAGgTASaEtS6n3lRWpRraSAAAeBBgQtjwpHgN6ttddY3N2vBJ5aXfAABAF0GACWG0kQAAaBsBJsS1tpE2f3aENhIAAGcRYELcUEecrurXXfW0kQAA8CDAhLhz20i5tJEAAJBEgDGF1jbSlrIjqj7TEORqAAAIPgKMCaQmxmlwv+6qb2rWetpIAAAQYMzAYrEoO73lCdWsRgIAgABjGq3PRsr/7Khcp2kjAQC6NgKMSQxJjNM1CT1a2ki7aSMBALo2AoyJtF7Mu7qENhIAoGsjwJhI63Lqd/ccoY0EAOjSCDAmck1inFIT49TQZCiPNhIAoAsjwJjMVM+zkQ4HuRIAAIKHAGMy2ekOSdK7e47KdYo2EgCgayLAmMzVCXEa6ohTY7OhtbudwS4HAICgIMCYULanjcRqJABA10SAMaGpZ5dTv7/3qE7U1ge5GgAAOh8BxoQG9+uhYUnxamw2tI42EgCgCyLAmFTrowVyaSMBALogAoxJtS6n3rrvmI7TRgIAdDEEGJMa1Le7RiTHq6nZ0LpS2kgAgK6FAGNiPBsJANBVEWBMLPucNtKxmrogVwMAQOchwJjYgD7dNfKKljbS2lKejQQA6Dp8DjD5+fm64447lJycLIvFolWrVnmONTQ0aO7cuUpLS1P37t2VnJysGTNm6PBh7+f2DBw4UBaLxWtbtGiR15ji4mLdfPPNiomJUUpKil588cWOzTDMZaclS5JWl/BsJABA1+FzgKmtrdWoUaO0ZMmS846dOnVKO3bs0M9+9jPt2LFDf//731VWVqZvfvOb54197rnnVFFR4dkee+wxzzG3263JkydrwIABKiws1OLFi7VgwQK99tprvpYb9lrbSAX7jukobSQAQBcR5esbsrKylJWV1eYxu92uvLw8r32//e1vdf3116u8vFxXXnmlZ39cXJwcDkebP2f58uWqr6/X0qVLZbVaNWLECBUVFemll17S7NmzfS05rF3ZJ1bp/e0qPuTSml1O3f8vA4JdEgAAARfwa2BcLpcsFot69uzptX/RokXq06ePxowZo8WLF6uxsdFzrKCgQOPHj5fVavXsy8zMVFlZmU6cONHm59TV1cntdnttXQXPRgIAdDUBDTBnzpzR3Llzde+99yo+Pt6z/0c/+pFWrFihTZs26eGHH9YLL7ygn/zkJ57jTqdTiYmJXj+r9bXT2fY9TxYuXCi73e7ZUlJSAjCj0NR6U7sP9h/TkWraSACA8BewANPQ0KC7775bhmHo1Vdf9TqWk5OjCRMmKD09XY888oh+9atf6ZVXXlFdXcf/+M6bN08ul8uzHTx48HKnYBopvWM1KqWnmg1pDTe1AwB0AQEJMK3h5YsvvlBeXp7Xty9tGTdunBobG3XgwAFJksPhUGWl97Lg1tcXum7GZrMpPj7ea+tKpnnaSKxGAgCEP78HmNbwsmfPHq1fv159+vS55HuKiooUERGhhIQESVJGRoby8/PV0NDgGZOXl6fU1FT16tXL3yWHhay0lmD3wf7jqqo+E+RqAAAILJ8DTE1NjYqKilRUVCRJ2r9/v4qKilReXq6Ghgb927/9mz766CMtX75cTU1Ncjqdcjqdqq9veeBgQUGBfvOb32jnzp36/PPPtXz5cj3xxBO6//77PeHkvvvuk9Vq1axZs1RaWqqVK1fq5ZdfVk5Ojv9mHmb694rV6JSeMgxpzS7aSACA8GYxDMPw5Q2bN2/Wrbfeet7+mTNnasGCBRo0aFCb79u0aZMmTJigHTt26N///d/16aefqq6uToMGDdIDDzygnJwc2Ww2z/ji4mLNmTNH27dvV9++ffXYY49p7ty57a7T7XbLbrfL5XJ1mXbSf7/7uX6++hNdP6i3/vJwRrDLAQDAZ+39++1zgDGLrhhgvjx5Wjcu2iiLRdo2b6IS42OCXRIAAD5p799vnoUURq7o2U3fuLKljfQOT6gGAIQxAkyYyU5vfTYSAQYAEL4IMGFm6tnVSNsPnJDTxWokAEB4IsCEmSR7N107oGU119t8CwMACFMEmDCUnd5yUzsCDAAgXBFgwlDWyJYA89EXJ1ThOh3kagAA8D8CTBhy2GN03cDWNhI3tQMAhB8CTJjK5tlIAIAwRoAJU1lpSbJYpB3lJ/XlSdpIAIDwQoAJU4nxMbpuYG9J3NQOABB+CDBhbNrZ1Ui5xQQYAEB4IcCEsSkjHbJYpKKDJ3Xw+KlglwMAgN8QYMJYQlyMxg0620baxbcwAIDwQYAJc189G4nl1ACA8EGACXNTRjgUYZF20kYCAIQRAkyY6xdn07hBfSTxaAEAQPggwHQBrc9GWk2AAQCECQJMFzBlZEsbqfiQS+XHaCMBAMyPANMF9O1hU8bgljYS38IAAMIBAaaLyE5rXY3Es5EAAOZHgOkiMkckKjLCol1funXgaG2wywEA4LIQYLqIPj1suoE2EgAgTBBgupDstJbVSCynBgCYHQGmC8kc4VBkhEWlh93aTxsJAGBiBJgupFd3q6eNxLcwAAAzI8B0MdPO3tQut5gAAwAwLwJMFzN5uENRERZ9UuHWviM1wS4HAIAOIcB0Mb26W3Xj1X0lSW/zLQwAwKQIMF0Qz0YCAJgdAaYLyhzuUHSkRZ86q7W3qjrY5QAA4DMCTBdkj43WTWfbSKuLnUGuBgAA3xFguqjsdJ6NBAAwLwJMF3X78ERFR1r0WWWN9lTSRgIAmAsBpouyd4vWzdf0k8TFvAAA8/E5wOTn5+uOO+5QcnKyLBaLVq1a5XXcMAzNnz9fSUlJ6tatmyZNmqQ9e/Z4jTl+/LimT5+u+Ph49ezZU7NmzVJNjfc9SYqLi3XzzTcrJiZGKSkpevHFF32fHS6q9dlIq1lODQAwGZ8DTG1trUaNGqUlS5a0efzFF1/Uf/7nf+p3v/udPvjgA3Xv3l2ZmZk6c+aMZ8z06dNVWlqqvLw85ebmKj8/X7Nnz/Ycd7vdmjx5sgYMGKDCwkItXrxYCxYs0GuvvdaBKeJCJg1PlDUyQnuqavQZbSQAgJkYl0GS8eabb3peNzc3Gw6Hw1i8eLFn38mTJw2bzWb8+c9/NgzDMHbv3m1IMrZv3+4Z88477xgWi8X48ssvDcMwjP/6r/8yevXqZdTV1XnGzJ0710hNTW13bS6Xy5BkuFyujk6vS5i17ENjwNxc41fryoJdCgAA7f777ddrYPbv3y+n06lJkyZ59tntdo0bN04FBQWSpIKCAvXs2VPXXnutZ8ykSZMUERGhDz74wDNm/PjxslqtnjGZmZkqKyvTiRMn2vzsuro6ud1urw2X5rmpXfFhGYYR5GoAAGgfvwYYp7PlniKJiYle+xMTEz3HnE6nEhISvI5HRUWpd+/eXmPa+hnnfsbXLVy4UHa73bOlpKRc/oS6gEnDEmWNitC+I7Uqo40EADCJsFmFNG/ePLlcLs928ODBYJdkCnEx0bplyNnVSFzMCwAwCb8GGIfDIUmqrKz02l9ZWek55nA4VFVV5XW8sbFRx48f9xrT1s849zO+zmazKT4+3mtD+0xL/2o1Em0kAIAZ+DXADBo0SA6HQxs2bPDsc7vd+uCDD5SRkSFJysjI0MmTJ1VYWOgZs3HjRjU3N2vcuHGeMfn5+WpoaPCMycvLU2pqqnr16uXPkiFp4tk20udHa/WpkzYSACD0+RxgampqVFRUpKKiIkktF+4WFRWpvLxcFotFjz/+uH7+85/rn//8p0pKSjRjxgwlJyfrzjvvlCQNGzZMU6ZM0UMPPaQPP/xQ77//vh599FHdc889Sk5uub39fffdJ6vVqlmzZqm0tFQrV67Uyy+/rJycHL9NHF/pYYvSBNpIAAAz8XV506ZNmwxJ520zZ840DKNlKfXPfvYzIzEx0bDZbMbEiRONsjLvJbrHjh0z7r33XqNHjx5GfHy88eCDDxrV1dVeY3bu3GncdNNNhs1mM6644gpj0aJFPtXJMmrfrPr4kDFgbq4xYfEmo7m5OdjlAAC6qPb+/bYYRnhe9OB2u2W32+Vyubgeph1q6ho19vk81TU2a/WPbtKIZHuwSwIAdEHt/fsdNquQcHl62KJ0a2rL8nbaSACAUEeAgYfnpnYlrEYCAIQ2Agw8bhuaoJjoCH1x7JRKD3MnYwBA6CLAwKO7LUq3DW1pI+XSRgIAhDACDLxkp7UsZV9dwrORAAChiwADL7cO7adu0ZE6ePy0dn1JGwkAEJoIMPASa43SbcPOtpFKDge5GgAA2kaAwXmy03g2EgAgtBFgcJ5bUxPULTpSh06cVvEhV7DLAQDgPAQYnKebNVITz7aRVpewGgkAEHoIMGjTtHTaSACA0EWAQZsmpCYo1hqpL0+eVtHBk8EuBwAALwQYtCkmOlKThiVK4tlIAIDQQ4DBBbU+G+ntkgo1N9NGAgCEDgIMLuiWIf3U3Rqpw64zKjp0MtjlAADgQYDBBcVER+r24bSRAAChhwCDi5qaRhsJABB6CDC4qPFD+qmHLUoVrjP6+OCJYJcDAIAkAgwu4dw2Ui5tJABAiCDA4JKyaSMBAEIMAQaXdPOQvoqzRanSXafCctpIAIDgI8DgkmxRkbp9BKuRAAChgwCDdpl2zk3tmmgjAQCCjACDdrnp6n6Ki4lSVXWdPjpwPNjlAAC6OAIM2sUaFaHMEQ5JLd/CAAAQTAQYtJtnNdIuJ20kAEBQEWDQbjde3VfxMVE6Ul2n7bSRAABBRIBBu53bRmI1EgAgmAgw8En22dVI7+xiNRIAIHgIMPDJjVf3lb1btI7W1OuD/ceCXQ4AoIsiwMAn0ZERmkIbCQAQZAQY+Ky1jbRml1ONTc1BrgYA0BURYOCzjMF91Cs2Wsdq6/XBflYjAQA6HwEGPouOjNCUkWfbSNzUDgAQBH4PMAMHDpTFYjlvmzNnjiRpwoQJ5x175JFHvH5GeXm5srOzFRsbq4SEBD311FNqbGz0d6m4DFPTaCMBAIInyt8/cPv27WpqavK83rVrl26//XZ95zvf8ex76KGH9Nxzz3lex8bGev7d1NSk7OxsORwObd26VRUVFZoxY4aio6P1wgsv+LtcdFDGVS1tpOO19dr2+XHddE3fYJcEAOhC/P4NTL9+/eRwODxbbm6uBg8erFtuucUzJjY21mtMfHy859i6deu0e/duvfHGGxo9erSysrL0/PPPa8mSJaqvr/d3ueigqMgITRnZ8i3M6pLDQa4GANDVBPQamPr6er3xxhv6/ve/L4vF4tm/fPly9e3bVyNHjtS8efN06tQpz7GCggKlpaUpMTHRsy8zM1Nut1ulpaUX/Ky6ujq53W6vDYE17ZzVSA20kQAAncjvLaRzrVq1SidPntT3vvc9z7777rtPAwYMUHJysoqLizV37lyVlZXp73//uyTJ6XR6hRdJntdOp/OCn7Vw4UI9++yz/p8ELmjcoN7q092qY7X1Kth3TOOH9At2SQCALiKgAeYPf/iDsrKylJyc7Nk3e/Zsz7/T0tKUlJSkiRMnat++fRo8eHCHP2vevHnKycnxvHa73UpJSenwz8OlRZ1djbT8g3KtLq4gwAAAOk3AWkhffPGF1q9frx/84AcXHTdu3DhJ0t69eyVJDodDlZWVXmNaXzscjgv+HJvNpvj4eK8Ngee5qV0pbSQAQOcJWIB5/fXXlZCQoOzs7IuOKyoqkiQlJbX8IczIyFBJSYmqqqo8Y/Ly8hQfH6/hw4cHqlx00LhBfdS3h1Wu0w16f+/RYJcDAOgiAhJgmpub9frrr2vmzJmKivqqS7Vv3z49//zzKiws1IEDB/TPf/5TM2bM0Pjx45Weni5Jmjx5soYPH64HHnhAO3fu1Nq1a/XTn/5Uc+bMkc1mC0S5uAyRERZlnV2N9DY3tQMAdJKABJj169ervLxc3//+9732W61WrV+/XpMnT9bQoUP15JNP6q677tJbb73lGRMZGanc3FxFRkYqIyND999/v2bMmOF13xiEltY20trSStU30kYCAASexTAMI9hFBILb7ZbdbpfL5eJ6mABrajY07oUNOlpTp9cfvE63piYEuyQAgEm19+83z0LCZYuMsGhq2tlnIxXTRgIABB4BBn6RndbaRnLSRgIABBwBBn5x7cDeSoizqfpMo97beyTY5QAAwhwBBn7R0kZq+RYmlzYSACDACDDwm9bVSHmllaprbLrEaAAAOo4AA78Ze2UvJcbbVF3XqHc/46Z2AIDAIcDAbyLOaSOt5qZ2AIAAIsDAr6adbSOt312pMw20kQAAgUGAgV+NSeklR3xMSxtpD20kAEBgEGDgV15tpOLDQa4GABCuCDDwO89qJNpIAIAAIcDA78ak9FSyPUa19U3a8hk3tQMA+B8BBn7n3UZiNRIAwP8IMAiI1jbS+k9oIwEA/I8Ag4AYndJTV/TsplP1TdpcVhXscgAAYYYAg4CwWCyeb2F4NhIAwN8IMAiY7LPXwWz8tEqn62kjAQD8hwCDgEnvb1f/XrSRAAD+R4BBwFgsFs+3MLk8GwkA4EcEGARU63UwGz+p0qn6xiBXAwAIFwQYBFTaFXal9O6m0w1N2vQpN7UDAPgHAQYB1dJGSpYkrS7h2UgAAP8gwCDgpqV/tRqpto42EgDg8hFgEHAjkuM1oE+szjQ0a+OnrEYCAFw+AgwC7tzVSDwbCQDgDwQYdIrW1UibymgjAQAuHwEGnWJ4UrwG9e2uusZmbaCNBAC4TAQYdAqLxaKpaQ5J0upiViMBAC4PAQadpnU59aayI6qhjQQAuAwEGHSaYUlxuqpvd9U3NmvDJ5XBLgcAYGIEGHQai8XiuZg3l9VIAIDLQIBBp2oNMFvKjqj6TEOQqwEAmBUBBp0qNTFOg/t1V31Ts9bTRgIAdBABBp2qpY109tlItJEAAB3k9wCzYMECWSwWr23o0KGe42fOnNGcOXPUp08f9ejRQ3fddZcqK73/S7y8vFzZ2dmKjY1VQkKCnnrqKTU2smolXLQ+Gyn/s6Ny00YCAHRAQL6BGTFihCoqKjzbe++95zn2xBNP6K233tJf//pXbdmyRYcPH9a3v/1tz/GmpiZlZ2ervr5eW7du1R//+EctW7ZM8+fPD0SpCIIhiXG6JqFHSxtpN20kAIDvAhJgoqKi5HA4PFvfvn0lSS6XS3/4wx/00ksv6bbbbtPYsWP1+uuva+vWrdq2bZskad26ddq9e7feeOMNjR49WllZWXr++ee1ZMkS1dfXB6JcBMFUno0EALgMAQkwe/bsUXJysq666ipNnz5d5eXlkqTCwkI1NDRo0qRJnrFDhw7VlVdeqYKCAklSQUGB0tLSlJiY6BmTmZkpt9ut0tLSC35mXV2d3G6314bQ1boaKX/PEblO00YCAPjG7wFm3LhxWrZsmdasWaNXX31V+/fv180336zq6mo5nU5ZrVb17NnT6z2JiYlyOp2SJKfT6RVeWo+3HruQhQsXym63e7aUlBT/Tgx+NSQxTkMSe6ihyVAebSQAgI/8HmCysrL0ne98R+np6crMzNTbb7+tkydP6i9/+Yu/P8rLvHnz5HK5PNvBgwcD+nm4fK2PFuDZSAAAXwV8GXXPnj01ZMgQ7d27Vw6HQ/X19Tp58qTXmMrKSjkcLQ/6czgc561Kan3dOqYtNptN8fHxXhtCW3Z6y/l8d89RuU7RRgIAtF/AA0xNTY327dunpKQkjR07VtHR0dqwYYPneFlZmcrLy5WRkSFJysjIUElJiaqqqjxj8vLyFB8fr+HDhwe6XHSiqxPiNNQRp8ZmQ2t3X7g9CADA1/k9wPy///f/tGXLFh04cEBbt27Vv/7rvyoyMlL33nuv7Ha7Zs2apZycHG3atEmFhYV68MEHlZGRoX/5l3+RJE2ePFnDhw/XAw88oJ07d2rt2rX66U9/qjlz5shms/m7XARZNquRAAAd4PcAc+jQId17771KTU3V3XffrT59+mjbtm3q16+fJOnXv/61pk2bprvuukvjx4+Xw+HQ3//+d8/7IyMjlZubq8jISGVkZOj+++/XjBkz9Nxzz/m7VISAqWdXI72/96hOnmKZPACgfSyGYRjBLiIQ3G637Ha7XC4X18OEuKyX39UnFW69eFe67r6O1WMA0JW19+83z0JC0GWntVzMm1tCGwkA0D4EGARd61153997VCdqaSMBAC6NAIOgu6pfDw1PildTs6G1paxGAgBcGgEGIaH10QKraSMBANqBAIOQ0Lqceuu+YzpWUxfkagAAoY4Ag5AwsG93jbyitY3Es5EAABdHgEHI8DwbqYRnIwEALo4Ag5DR2kYq2HdMR2kjAQAuggCDkHFln1il97er2RCrkQAAF0WAQUiZyrORAADtQIBBSGltI237/JiOVNNGAgC0jQCDkJLSO1ajzraR1tBGAgBcAAEGIcdzU7tiViMBANpGgEHIab0O5oP9x1VVfSbI1QAAQhEBBiGnf69YjU7pKcOQ1uyijQQAOB8BBiFp2tk2Ui6rkQAAbSDAICRlnW0jbT9wXFVu2kgAAG8EGISkK3p20zeubGkjvUMbCQDwNQQYhKzs9LPPRqKNBAD4GgIMQtbUNIckafsXx+V00UYCAHyFAIOQlWTvprEDep1tI/EtDADgKwQYhLRsno0EAGgDAQYhrfWmdh99cUIVrtNBrgYAECoIMAhpDnuMrhvYS5L0dgmrkQAALQgwCHlftZF4NhIAoAUBBiEvKy1JFou0o/ykvjxJGwkAQICBCSTGx+i6gb0lSe+UcDEvAIAAA5NofTbSagIMAEAEGJjElJEOWSzSx+UndejEqWCXAwAIMgIMTCEhLkbXe9pIrEYCgK6OAAPTaG0j5dJGAoAujwAD08gc6VCERdp58KQOHqeNBABdGQEGppEQF6Nxg/pIkt7mWxgA6NIIMDCVbFYjAQAUgACzcOFCXXfddYqLi1NCQoLuvPNOlZWVeY2ZMGGCLBaL1/bII494jSkvL1d2drZiY2OVkJCgp556So2Njf4uFyYz5WwbqfiQS+XHaCMBQFfl9wCzZcsWzZkzR9u2bVNeXp4aGho0efJk1dbWeo176KGHVFFR4dlefPFFz7GmpiZlZ2ervr5eW7du1R//+EctW7ZM8+fP93e5MJm+PWzKGNzSRuJbGADouqL8/QPXrFnj9XrZsmVKSEhQYWGhxo8f79kfGxsrh8PR5s9Yt26ddu/erfXr1ysxMVGjR4/W888/r7lz52rBggWyWq3+Lhsmkp2WrPf3HtPbJRX64YTBwS4HABAEAb8GxuVySZJ69+7ttX/58uXq27evRo4cqXnz5unUqa/aAQUFBUpLS1NiYqJnX2Zmptxut0pLS9v8nLq6Orndbq8N4SlzRKIiIywq+dKlL47VXvoNAICwE9AA09zcrMcff1w33nijRo4c6dl/33336Y033tCmTZs0b948/elPf9L999/vOe50Or3CiyTPa6ez7ZuYLVy4UHa73bOlpKQEYEYIBX162JRxFW0kAOjK/N5COtecOXO0a9cuvffee177Z8+e7fl3WlqakpKSNHHiRO3bt0+DB3esJTBv3jzl5OR4XrvdbkJMGMtOT9J7e49qdXGF/n3C1cEuBwDQyQL2Dcyjjz6q3Nxcbdq0Sf3797/o2HHjxkmS9u7dK0lyOByqrKz0GtP6+kLXzdhsNsXHx3ttCF+ZIxyKjLCo9LBb+4/SRgKArsbvAcYwDD366KN68803tXHjRg0aNOiS7ykqKpIkJSW13OMjIyNDJSUlqqqq8ozJy8tTfHy8hg8f7u+SYUK9u1t1w2BuagcAXZXfA8ycOXP0xhtv6H//938VFxcnp9Mpp9Op06dPS5L27dun559/XoWFhTpw4ID++c9/asaMGRo/frzS09MlSZMnT9bw4cP1wAMPaOfOnVq7dq1++tOfas6cObLZbP4uGSbleTZSMQEGALoavweYV199VS6XSxMmTFBSUpJnW7lypSTJarVq/fr1mjx5soYOHaonn3xSd911l9566y3Pz4iMjFRubq4iIyOVkZGh+++/XzNmzNBzzz3n73JhYpOHOxQVYdEnFW7tO1IT7HIAAJ3IYhiGEewiAsHtdstut8vlcnE9TBibufRDbfnsiJ68fYgem3hNsMsBAFym9v795llIMDWejQQAXRMBBqY2eXiioiIs+tRZrb1VtJEAoKsgwMDUesZaddM1fSWxGgkAuhICDEwvO+1sG4nVSADQZRBgYHqThzsUHWlRWWW19lRWB7scAEAnIMDA9Oyx0br5mn6SuJgXALoKAgzCAm0kAOhaCDAIC5OGJ8oaGaE9VTX6jDYSAIQ9AgzCgr1btMYPaVmNxKMFACD8EWAQNjw3tSs+rDC9wTQA4CwCDMLGpGGJskZFaN+RWn1WyU3tACCcEWAQNuJiojW+dTVS8eEgVwMACCQCDMLKtLNtpNySCtpIABDGCDAIKxOHJcgaFaHPj9TqUyerkQAgXBFgEFbiYqI1YUhrG4nVSAAQrggwCDue1Ui0kQAgbBFgEHYmDkuULSpC+4/WaneFO9jlAAACgACDsNPDFqVbUxMk0UYCgHBFgEFYoo0EAOGNAIOwdNvQBMVER+iLY6dUepg2EgCEGwIMwlL3c9tIJbSRACDcEGAQtr56NhJtJAAINwQYhK3WNlL58VPa9SVtJAAIJwQYhK1Ya5QmDk2UJOWW8GwkAAgnBBiENdpIABCeCDAIa7emJqhbdKQOnTit4kOuYJcDAPATAgzCWjdrpCYOYzUSAIQbAgzC3jTaSAAQdggwCHsTUhMUa43UlydPaydtJAAICwQYhL2Y6EhNHNayGml1MauRACAcEGDQJWSn0UYCgHBCgEGXMCG1n7pbI3XYdUYfHzwZ7HIAAJeJAIMuISY6UpOGt7aRWI0EAGYX0gFmyZIlGjhwoGJiYjRu3Dh9+OGHwS4JJtbaRnq7pELNzbSRAMDMQjbArFy5Ujk5OXrmmWe0Y8cOjRo1SpmZmaqqqgp2aTCp8UP6qYctShWuM/r44IlglwMAuAwhG2BeeuklPfTQQ3rwwQc1fPhw/e53v1NsbKyWLl0a7NJgUjHRkbr9bBsplzYSAJhaVLALaEt9fb0KCws1b948z76IiAhNmjRJBQUFQawMZpedlqQ3P/5S/yg6rMamzm0jWSyd+nHq5I+TpbMnCCDo/m1sf428wh6Uzw7JAHP06FE1NTUpMTHRa39iYqI+/fTTNt9TV1enuro6z2u32x3QGmFONw/pq/iYKB2vrdeftn0R7HIAwNS+MaAXAeZyLVy4UM8++2ywy0CIs0VF6vUHr1f+Z0c69XM7/ZLhTr7XTWfPj1v5AKHhmoQeQfvskAwwffv2VWRkpCorK732V1ZWyuFwtPmeefPmKScnx/Pa7XYrJSUloHXCnMYO6KWxA3oFuwwAwGUIyYt4rVarxo4dqw0bNnj2NTc3a8OGDcrIyGjzPTabTfHx8V4bAAAITyH5DYwk5eTkaObMmbr22mt1/fXX6ze/+Y1qa2v14IMPBrs0AAAQZCEbYL773e/qyJEjmj9/vpxOp0aPHq01a9acd2EvAADoeixGmD7Zzu12y263y+Vy0U4CAMAk2vv3OySvgQEAALgYAgwAADAdAgwAADAdAgwAADAdAgwAADAdAgwAADAdAgwAADAdAgwAADAdAgwAADCdkH2UwOVqvcGw2+0OciUAAKC9Wv9uX+pBAWEbYKqrqyVJKSkpQa4EAAD4qrq6Wna7/YLHw/ZZSM3NzTp8+LDi4uJksVj89nPdbrdSUlJ08ODBsH3GUrjPkfmZX7jPMdznJ4X/HJlfxxmGoerqaiUnJysi4sJXuoTtNzARERHq379/wH5+fHx8WP6f8lzhPkfmZ37hPsdwn58U/nNkfh1zsW9eWnERLwAAMB0CDAAAMB0CjI9sNpueeeYZ2Wy2YJcSMOE+R+ZnfuE+x3CfnxT+c2R+gRe2F/ECAIDwxTcwAADAdAgwAADAdAgwAADAdAgwAADAdAgwbViyZIkGDhyomJgYjRs3Th9++OFFx//1r3/V0KFDFRMTo7S0NL399tudVGnH+TLHZcuWyWKxeG0xMTGdWK1v8vPzdccddyg5OVkWi0WrVq265Hs2b96sb3zjG7LZbLr66qu1bNmygNfZUb7Ob/PmzeedP4vFIqfT2TkF+2jhwoW67rrrFBcXp4SEBN15550qKyu75PvM8nvYkfmZ7Xfw1VdfVXp6uucmZxkZGXrnnXcu+h6znD/J9/mZ7fx93aJFi2SxWPT4449fdFxnn0MCzNesXLlSOTk5euaZZ7Rjxw6NGjVKmZmZqqqqanP81q1bde+992rWrFn6+OOPdeedd+rOO+/Url27Orny9vN1jlLL3RYrKio82xdffNGJFfumtrZWo0aN0pIlS9o1fv/+/crOztatt96qoqIiPf744/rBD36gtWvXBrjSjvF1fq3Kysq8zmFCQkKAKrw8W7Zs0Zw5c7Rt2zbl5eWpoaFBkydPVm1t7QXfY6bfw47MTzLX72D//v21aNEiFRYW6qOPPtJtt92mb33rWyotLW1zvJnOn+T7/CRznb9zbd++Xb///e+Vnp5+0XFBOYcGvFx//fXGnDlzPK+bmpqM5ORkY+HChW2Ov/vuu43s7GyvfePGjTMefvjhgNZ5OXyd4+uvv27Y7fZOqs6/JBlvvvnmRcf85Cc/MUaMGOG177vf/a6RmZkZwMr8oz3z27RpkyHJOHHiRKfU5G9VVVWGJGPLli0XHGPG38NW7ZmfmX8HW/Xq1cv47//+7zaPmfn8tbrY/Mx6/qqrq41rrrnGyMvLM2655Rbjxz/+8QXHBuMc8g3MOerr61VYWKhJkyZ59kVERGjSpEkqKCho8z0FBQVe4yUpMzPzguODrSNzlKSamhoNGDBAKSkpl/wvDbMx2znsqNGjRyspKUm333673n///WCX024ul0uS1Lt37wuOMfM5bM/8JPP+DjY1NWnFihWqra1VRkZGm2PMfP7aMz/JnOdvzpw5ys7OPu/ctCUY55AAc46jR4+qqalJiYmJXvsTExMveL2A0+n0aXywdWSOqampWrp0qf7xj3/ojTfeUHNzs2644QYdOnSoM0oOuAudQ7fbrdOnTwepKv9JSkrS7373O/3tb3/T3/72N6WkpGjChAnasWNHsEu7pObmZj3++OO68cYbNXLkyAuOM9vvYav2zs+Mv4MlJSXq0aOHbDabHnnkEb355psaPnx4m2PNeP58mZ8Zz9+KFSu0Y8cOLVy4sF3jg3EOw/Zp1PCfjIwMr/+yuOGGGzRs2DD9/ve/1/PPPx/EytAeqampSk1N9by+4YYbtG/fPv3617/Wn/70pyBWdmlz5szRrl279N577wW7lIBo7/zM+DuYmpqqoqIiuVwu/d///Z9mzpypLVu2XPCPvNn4Mj+znb+DBw/qxz/+sfLy8kL6YmMCzDn69u2ryMhIVVZWeu2vrKyUw+Fo8z0Oh8On8cHWkTl+XXR0tMaMGaO9e/cGosROd6FzGB8fr27dugWpqsC6/vrrQz4UPProo8rNzVV+fr769+9/0bFm+z2UfJvf15nhd9Bqterqq6+WJI0dO1bbt2/Xyy+/rN///vfnjTXj+fNlfl8X6uevsLBQVVVV+sY3vuHZ19TUpPz8fP32t79VXV2dIiMjvd4TjHNIC+kcVqtVY8eO1YYNGzz7mpubtWHDhgv2NjMyMrzGS1JeXt5Fe6HB1JE5fl1TU5NKSkqUlJQUqDI7ldnOoT8UFRWF7PkzDEOPPvqo3nzzTW3cuFGDBg265HvMdA47Mr+vM+PvYHNzs+rq6to8ZqbzdyEXm9/Xhfr5mzhxokpKSlRUVOTZrr32Wk2fPl1FRUXnhRcpSOcwYJcHm9SKFSsMm81mLFu2zNi9e7cxe/Zso2fPnobT6TQMwzAeeOAB4+mnn/aMf//9942oqCjjl7/8pfHJJ58YzzzzjBEdHW2UlJQEawqX5Oscn332WWPt2rXGvn37jMLCQuOee+4xYmJijNLS0mBN4aKqq6uNjz/+2Pj4448NScZLL71kfPzxx8YXX3xhGIZhPP3008YDDzzgGf/5558bsbGxxlNPPWV88sknxpIlS4zIyEhjzZo1wZrCRfk6v1//+tfGqlWrjD179hglJSXGj3/8YyMiIsJYv359sKZwUT/84Q8Nu91ubN682aioqPBsp06d8owx8+9hR+Zntt/Bp59+2tiyZYuxf/9+o7i42Hj66acNi8VirFu3zjAMc58/w/B9fmY7f235+iqkUDiHBJg2vPLKK8aVV15pWK1W4/rrrze2bdvmOXbLLbcYM2fO9Br/l7/8xRgyZIhhtVqNESNGGKtXr+7kin3nyxwff/xxz9jExERj6tSpxo4dO4JQdfu0Lhv++tY6p5kzZxq33HLLee8ZPXq0YbVajauuusp4/fXXO73u9vJ1fr/4xS+MwYMHGzExMUbv3r2NCRMmGBs3bgxO8e3Q1twkeZ0TM/8edmR+Zvsd/P73v28MGDDAsFqtRr9+/YyJEyd6/rgbhrnPn2H4Pj+znb+2fD3AhMI5tBiGYQTu+x0AAAD/4xoYAABgOgQYAABgOgQYAABgOgQYAABgOgQYAABgOgQYAABgOgQYAABgOgQYAABgOgQYAABgOgQYAABgOgQYAABgOgQYAABgOv8fl5I5EhoMd3kAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_all)\n",
    "# plt.plot(loss_valid_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Detected the following values in `preds`: tensor([2], device='cuda:0') but expected only the following values [0,1] since `preds` is a label tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[72]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m test_data_batches:\n\u001b[32m      6\u001b[39m     pred = model(batch.x, batch.edge_index).argmax(dim=\u001b[32m1\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m     scores = \u001b[43mgroundtruth_metrics\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpred_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpred\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_mask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_mask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43maccuracy\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprecision\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrecall\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mf1_score\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     avg_scores += [scores]\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/smcs/lib/python3.12/site-packages/torch_geometric/explain/metric/basic.py:52\u001b[39m, in \u001b[36mgroundtruth_metrics\u001b[39m\u001b[34m(pred_mask, target_mask, metrics, threshold)\u001b[39m\n\u001b[32m     50\u001b[39m         out = fn(pred_mask, target_mask, \u001b[33m'\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         out = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpred_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mbinary\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m     outs.append(\u001b[38;5;28mfloat\u001b[39m(out))\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(outs) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(outs) > \u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m outs[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/smcs/lib/python3.12/site-packages/torchmetrics/functional/classification/accuracy.py:419\u001b[39m, in \u001b[36maccuracy\u001b[39m\u001b[34m(preds, target, task, threshold, num_classes, num_labels, average, multidim_average, top_k, ignore_index, validate_args)\u001b[39m\n\u001b[32m    416\u001b[39m task = ClassificationTask.from_str(task)\n\u001b[32m    418\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m task == ClassificationTask.BINARY:\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_accuracy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultidim_average\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m task == ClassificationTask.MULTICLASS:\n\u001b[32m    421\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(num_classes, \u001b[38;5;28mint\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/smcs/lib/python3.12/site-packages/torchmetrics/functional/classification/accuracy.py:160\u001b[39m, in \u001b[36mbinary_accuracy\u001b[39m\u001b[34m(preds, target, threshold, multidim_average, ignore_index, validate_args)\u001b[39m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m validate_args:\n\u001b[32m    159\u001b[39m     _binary_stat_scores_arg_validation(threshold, multidim_average, ignore_index)\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m     \u001b[43m_binary_stat_scores_tensor_validation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultidim_average\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m preds, target = _binary_stat_scores_format(preds, target, threshold, ignore_index)\n\u001b[32m    162\u001b[39m tp, fp, tn, fn = _binary_stat_scores_update(preds, target, multidim_average)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/smcs/lib/python3.12/site-packages/torchmetrics/functional/classification/stat_scores.py:86\u001b[39m, in \u001b[36m_binary_stat_scores_tensor_validation\u001b[39m\u001b[34m(preds, target, multidim_average, ignore_index)\u001b[39m\n\u001b[32m     84\u001b[39m     unique_values = torch.unique(preds, dim=\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     85\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch.any((unique_values != \u001b[32m0\u001b[39m) & (unique_values != \u001b[32m1\u001b[39m)):\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m     87\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDetected the following values in `preds`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00munique_values\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m but expected only\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     88\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m the following values [0,1] since `preds` is a label tensor.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     89\u001b[39m         )\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m multidim_average != \u001b[33m\"\u001b[39m\u001b[33mglobal\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m preds.ndim < \u001b[32m2\u001b[39m:\n\u001b[32m     92\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mExpected input to be at least 2D when multidim_average is set to `samplewise`\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: Detected the following values in `preds`: tensor([2], device='cuda:0') but expected only the following values [0,1] since `preds` is a label tensor."
     ]
    }
   ],
   "source": [
    "from torch_geometric.explain.metric import groundtruth_metrics\n",
    "\n",
    "avg_scores = []\n",
    "model.eval()\n",
    "for batch in test_data_batches:\n",
    "    pred = model(batch.x, batch.edge_index).argmax(dim=1)\n",
    "    scores = groundtruth_metrics(\n",
    "        pred_mask=pred[batch.train_mask],\n",
    "        target_mask=batch.y[batch.train_mask],\n",
    "        threshold=0.5,\n",
    "        metrics=[\"accuracy\", \"precision\", \"recall\", \"f1_score\"]\n",
    "    )\n",
    "    avg_scores += [scores]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.asarray(avg_scores).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.explain.metric import groundtruth_metrics\n",
    "\n",
    "avg_scores = []\n",
    "model.eval()\n",
    "skips = 0\n",
    "for batch in tqdm(loader, total=data.x.shape[0]//batch_size):\n",
    "    if batch.test_mask.sum() <= 0:\n",
    "        skips += 1\n",
    "        continue\n",
    "    pred = model(batch.x, batch.edge_index).argmax(dim=1)\n",
    "\n",
    "    scores = groundtruth_metrics(\n",
    "        pred_mask=pred[batch.test_mask],\n",
    "        target_mask=batch.y[batch.test_mask],\n",
    "        threshold=0.5,\n",
    "        metrics=[\"accuracy\", \"precision\", \"recall\", \"f1_score\"]\n",
    "    )\n",
    "    avg_scores += [scores]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "print(f\"Skips = {skips}\")\n",
    "np.asarray(avg_scores).mean(axis=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smcs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
