{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_processing import *\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# DEVICE = torch.device(\"cpu\")\n",
    "train_data, OUT_DIM = load_create_ellipticpp(timestep=(1,32))\n",
    "train_data = train_data.to(DEVICE)\n",
    "valid_data, OUT_DIM = load_create_ellipticpp(timestep=(33,37))\n",
    "valid_data = valid_data.to(DEVICE)\n",
    "test_data, OUT_DIM = load_create_ellipticpp(timestep=(38,42))\n",
    "test_data = test_data.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @ TODO: NEED TO CONSIDER TIME EDGE ATTRIBUTE!!!!\n",
    "# from data_processing import *\n",
    "\n",
    "# # DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "# train_data, OUT_DIM = load_dgraphfin()\n",
    "# train_data = train_data.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maybe remvoe mask and cosnider temporal split for elliptic++\n",
    "# dataloader (from pt) - implement sampler here -> neighourloader\n",
    "# summary stats on avg degree of a node when considering ([-1,-1] neighbourhoods)\n",
    "# graphsage/gat with full neighbourhood, 75%/50%/25% reduction in neighbourhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batching_script import *\n",
    "\n",
    "train_batches = customBatching(train_data, positive_label=1, negative_label=0, neighbourhood_sizes=[10,5], batch_size=64)\n",
    "valid_batches = customBatching(valid_data, positive_label=1, negative_label=0, neighbourhood_sizes=[-1] * 2, batch_size=64)\n",
    "test_batches = customBatching(test_data, positive_label=1, negative_label=0, neighbourhood_sizes=[-1] * 2, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# remove timestep attribute !!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv, GCNConv, GATConv\n",
    "\n",
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, **layer_paras):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_layers = layer_paras.pop(\"num_layers\",1)\n",
    "        self.hidden_dim = layer_paras.pop(\"hidden_channels\")\n",
    "        self.cached = layer_paras.pop(\"cached\", True)\n",
    "\n",
    "        self.dropout = layer_paras.pop(\"dropout\", 0.0)\n",
    "\n",
    "        self.conv_layers = []\n",
    "\n",
    "        ###### BAD ???????\n",
    "        # self.conv_layers += [\n",
    "        #     SAGEConv(in_dim, self.hidden_dim) # input layer; cached=True => for transductive learning\n",
    "        # ]\n",
    "        # for _ in range(self.num_layers-1):\n",
    "        #     self.conv_layers += [\n",
    "        #         SAGEConv(self.hidden_dim, self.hidden_dim)\n",
    "        #     ]\n",
    "        # self.conv_layers += [\n",
    "        #     SAGEConv(self.hidden_dim, out_dim) # output layer; cached=True => for transductive learning\n",
    "        # ]\n",
    "        ###### BAD ???????\n",
    "\n",
    "        ##### SAGE-ATTN\n",
    "        self.conv_layers += [SAGEConv(in_dim, self.hidden_dim)]\n",
    "        self.conv_layers += [GATConv(self.hidden_dim, out_dim, heads=3)]\n",
    "\n",
    "        ##### SAGE 1-layer\n",
    "        # self.conv_layers += [SAGEConv(in_dim, out_dim)]\n",
    "\n",
    "        ##### GAT \n",
    "        # self.conv_layers += [GATConv(in_dim, out_dim)]\n",
    "\n",
    "        ##### GCN\n",
    "        # self.conv_layers += [GCNConv(in_dim, out_dim)]\n",
    "\n",
    "        \n",
    "        self.conv_layers = torch.nn.ParameterList(self.conv_layers)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for conv in self.conv_layers[:-1]:\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, training=self.training, p=self.dropout)\n",
    "        x = self.conv_layers[-1](x, edge_index)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAGE(\n",
      "  (conv_layers): ParameterList(\n",
      "      (0): Object of type: SAGEConv\n",
      "      (1): Object of type: GATConv\n",
      "    (0): SAGEConv(55, 55, aggr=mean)\n",
      "    (1): GATConv(55, 3, heads=3)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "paras = {\n",
    "    'lr':0.005,\n",
    "    'num_layers':2,\n",
    "    'hidden_channels':55,\n",
    "    'dropout':0.4,\n",
    "    'batchnorm': False,\n",
    "    'l2':5e-3,\n",
    "    'cached': True,\n",
    "}\n",
    "\n",
    "### ablation/sensitivity study - look at sampling factor\n",
    "## do study on valid data - then best config on test data\n",
    "## 10 training runs and avg\n",
    "\n",
    "# @TODO: REMOVE UNKNOWN CLASS !!!!\n",
    "model = SAGE(in_dim=train_data.x.shape[1], out_dim=3, **paras).to(DEVICE)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=paras[\"lr\"], weight_decay=paras[\"l2\"])\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 3/3; Batch: 576/576; Loss=0.0000; Loss-Validation=0.0000: 100%|██████████| 3/3 [00:31<00:00, 10.45s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(batches, model, optimizer, epoch_num=1):\n",
    "    loss_all = []\n",
    "    loss_valid_all = []\n",
    "\n",
    "    model.train()\n",
    "    iterator = tqdm(range(epoch_num), desc=\"\")\n",
    "    for epoch in iterator:\n",
    "        running_loss = 0\n",
    "        valid_loss = 0\n",
    "        for idx, batch in enumerate(batches):\n",
    "            out = model(batch.x, batch.edge_index)\n",
    "\n",
    "            loss = F.cross_entropy(out[batch.train_mask], batch.y[batch.train_mask])\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            ### @TODO: early stopping criterion + patience\n",
    "\n",
    "            # iterator.set_description(f\"Epoch: {epoch+1}/{epoch_num}; Batch: {idx+1}/{len(batches)}; Loss: {loss.item()/(idx+1):0.4f}\")\n",
    "\n",
    "        # loss_valid = F.cross_entropy(out[batch.val_mask], batch.y[batch.val_mask])\n",
    "        # running_valid_loss += loss_valid.item()    \n",
    "        # iterator.set_description(f\"Epoch: {epoch+1}/{epoch_num}; Batch: {idx+1}/{data.x.shape[0]//batch_size}; Loss: {running_loss/(idx+1):0.4f}\")\n",
    "        # @TODO: add validation round to monitor performance\n",
    "        # loss_all += [running_loss/(data.x.shape[0]//batch_size)]\n",
    "        # loss_valid_all += [running_valid_loss/(data.x.shape[0]//batch_size)]\n",
    "\n",
    "        loss_all += [running_loss/(idx+1)]\n",
    "        loss_valid_all += [valid_loss]\n",
    "\n",
    "        iterator.set_description(f\"Epoch: {epoch+1}/{epoch_num}; Batch: {idx+1}/{len(batches)}; Loss={loss_all[-1]:.4f}; Loss-Validation={loss_valid_all[-1]:.4f}\")\n",
    "\n",
    "    return loss_all, loss_valid_all\n",
    "\n",
    "# 1-33 33-37 - train on first then test on second; at the end, test on testing set after training on all 1-37\n",
    "\n",
    "loss_all, loss_valid_all = train(train_batches, model, optimizer, epoch_num=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x71a716564470>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_all)\n",
    "# plt.plot(loss_valid_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 90/90 [00:01<00:00, 67.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix [[1108.0, 5728.0], [2795.0, 51659.0]]\n",
      "Accuracy=0.7957683205604553\n",
      "Precision=0.30939480662345886\n",
      "Recall=0.19766461849212646\n",
      "F1=0.30939480662345886\n",
      "Auroc=nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.explain.metric import groundtruth_metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "\n",
    "def compute_cm(orig_labels, pred_labels, positive_label, negative_label):\n",
    "    tp = ((orig_labels == pred_labels) & (orig_labels == positive_label)).sum()\n",
    "    tn = ((orig_labels == pred_labels) & (orig_labels == negative_label)).sum()\n",
    "    fn = ((orig_labels != pred_labels) & (orig_labels == positive_label)).sum()\n",
    "    fp = ((orig_labels != pred_labels) & (orig_labels == negative_label)).sum()\n",
    "\n",
    "    return torch.as_tensor([[tp, fn], [fp, tn]])\n",
    "\n",
    "def compute_accuracy(cm: torch.Tensor):\n",
    "    return (cm.diagonal().sum() / cm.sum()).item() if cm.sum().item() != 0 else 0\n",
    "\n",
    "def compute_precision(cm):\n",
    "    score = (cm[0,0] / cm[:,0].sum()) \n",
    "    return score.item() if not torch.isnan(score) else 0\n",
    "\n",
    "def compute_recall(cm):\n",
    "    score = (cm[0,0] / cm[0,:].sum()) \n",
    "    return score.item() if not torch.isnan(score) else 0\n",
    "\n",
    "def compute_f1(cm, precision=None, recall=None):\n",
    "    if not (precision and recall):\n",
    "        precision = compute_precision(cm)\n",
    "        recall = compute_precision(cm)\n",
    "\n",
    "    return (2*precision*recall)/(precision+recall) if precision + recall > 0 else 0\n",
    "\n",
    "def compute_metrics(cm):\n",
    "    metrics = [compute_accuracy, compute_precision, compute_recall, compute_f1]\n",
    "    results = {}\n",
    "    for metric in metrics:\n",
    "        results[metric.__name__.split(\"_\")[-1]] = metric(cm)\n",
    "\n",
    "    return results\n",
    "\n",
    "avg_scores = []\n",
    "model.eval()\n",
    "\n",
    "acc = []\n",
    "metrics = {\n",
    "    \"accuracy\": [],\n",
    "    \"precision\": [],\n",
    "    \"recall\": [],\n",
    "    \"f1\": [],\n",
    "    \"auroc\": [],\n",
    "}\n",
    "positive_label = 1\n",
    "negative_label = 0\n",
    "cm_total = torch.zeros((2,2))\n",
    "cm_total_sk = np.zeros((2,2))\n",
    "\n",
    "\n",
    "for batch in tqdm(test_batches):\n",
    "    pred = model(batch.x, batch.edge_index)\n",
    "\n",
    "    pred_labels = pred.argmax(dim=1)\n",
    "    orig_labels = batch.y\n",
    "    cm = compute_cm(orig_labels, pred_labels, positive_label=positive_label, negative_label=negative_label)\n",
    "\n",
    "    results = compute_metrics(cm)\n",
    "    cm_total += cm\n",
    "\n",
    "    for metric, score in results.items():\n",
    "        metrics[metric] += [score]\n",
    "\n",
    "    acc += [(orig_labels == pred_labels).sum()/orig_labels.shape[0]]\n",
    "\n",
    "    scores = groundtruth_metrics(\n",
    "        pred_mask=pred[batch.train_mask].max(dim=1)[1],\n",
    "        target_mask=batch.y[batch.train_mask],\n",
    "        threshold=0.5,\n",
    "        metrics=[\"accuracy\", \"precision\", \"recall\", \"f1_score\"]\n",
    "    )\n",
    "    avg_scores += [scores]\n",
    "\n",
    "print(\"Confusion Matrix\", cm_total.tolist())\n",
    "for metric, scores in metrics.items():\n",
    "    print(f\"{metric.title()}={torch.mean(torch.as_tensor(scores, dtype=torch.float32))}\")\n",
    "import numpy as np\n",
    "# print(np.mean(acc))\n",
    "\n",
    "# np.asarray(avg_scores).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########## METRICS LIBRARY\n",
    "# accuracy | precision | recall | F1\n",
    "\n",
    "###### PURE 1-LAYER SAGE\n",
    "# array([0.70954861, 0.70012975, 0.74131944, 0.71829656])\n",
    "\n",
    "###### PURE 1-LAYER GAT\n",
    "# array([0.53819444, 0.52934275, 0.71319444, 0.60629397])\n",
    "\n",
    "##### SAGE-ATTN\n",
    "# array([0.503125  , 0.50161935, 0.98715278, 0.66517364])\n",
    "\n",
    "###### PURE 1-LAYER GCN\n",
    "# array([0.6640625 , 0.63122737, 0.80381944, 0.70562114])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### PURE 1-LAYER SAGECONV\n",
    "# Confusion Matrix [[6281.0, 555.0], [47872.0, 6582.0]]\n",
    "# Accuracy=0.26841437816619873\n",
    "# Precision=0.18005317449569702\n",
    "# Recall=0.9099577069282532\n",
    "# F1=0.18005317449569702\n",
    "# Auroc=nan\n",
    "\n",
    "##### PURE 1-LAYER GAT\n",
    "# Confusion Matrix [[6047.0, 789.0], [34203.0, 20251.0]]\n",
    "# Accuracy=0.4496999979019165\n",
    "# Precision=0.21606987714767456\n",
    "# Recall=0.884824812412262\n",
    "# F1=0.21606987714767456\n",
    "# Auroc=nan\n",
    "\n",
    "##### SAGE-ATTN\n",
    "# Confusion Matrix [[1196.0, 5640.0], [18660.0, 35794.0]]\n",
    "# Accuracy=0.5885034203529358\n",
    "# Precision=0.12076546251773834\n",
    "# Recall=0.19161765277385712\n",
    "# F1=0.12076546251773834\n",
    "# Auroc=nan\n",
    "\n",
    "###### PURE 1-LAYER GCN\n",
    "# Confusion Matrix [[5111.0, 1725.0], [17802.0, 36652.0]]\n",
    "# Accuracy=0.6739125847816467\n",
    "# Precision=0.29481324553489685\n",
    "# Recall=0.7564181685447693\n",
    "# F1=0.29481324553489685\n",
    "# Auroc=nan\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smcs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
