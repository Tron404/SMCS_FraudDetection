{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[51108, 55], y=[51108], edge_index=[2, 84088], train_mask=[51108], val_mask=[51108], test_mask=[51108])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data_processing import *\n",
    "\n",
    "data, OUT_DIM = load_create_ellipticpp()\n",
    "batch_size = 10\n",
    "loader = split_into_batches(data, num_batches=batch_size, num_hops=2, num_neighbours=100)\n",
    "num_features = next(iter(loader)).x.shape[-1]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[14, 55], y=[14], edge_index=[2, 26], train_mask=[14], val_mask=[14], test_mask=[14], n_id=[14], e_id=[26], num_sampled_nodes=[3], num_sampled_edges=[2], input_id=[10], batch_size=10)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, **layer_paras):\n",
    "        super().__init__()\n",
    "\n",
    "        self.num_layers = layer_paras.pop(\"num_layers\",2)\n",
    "        self.hidden_dim = layer_paras.pop(\"hidden_channels\")\n",
    "        self.cached = layer_paras.pop(\"cached\", True)\n",
    "\n",
    "        self.dropout = layer_paras.pop(\"dropout\", 0.0)\n",
    "\n",
    "        self.conv_layers = []\n",
    "\n",
    "        self.conv_layers += [\n",
    "            SAGEConv(in_dim, self.hidden_dim) # input layer; cached=True => for transductive learning\n",
    "        ]\n",
    "        for _ in range(self.num_layers-2):\n",
    "            self.conv_layers += [\n",
    "                SAGEConv(self.hidden_dim, self.hidden_dim)\n",
    "            ]\n",
    "        self.conv_layers += [\n",
    "            SAGEConv(self.hidden_dim, out_dim) # output layer; cached=True => for transductive learning\n",
    "        ]\n",
    "\n",
    "        self.conv_layers = torch.nn.ParameterList(self.conv_layers)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for conv in self.conv_layers[:-1]:\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, training=self.training, p=self.dropout)\n",
    "        x = self.conv_layers[-1](x, edge_index)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "paras = {\n",
    "    'lr':0.01,\n",
    "    'num_layers':4,\n",
    "    'hidden_channels':128,\n",
    "    'dropout':0.0,\n",
    "    'batchnorm': False,\n",
    "    'l2':5e-7,\n",
    "    'cached': True,\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SAGE(\n",
       "  (conv_layers): ParameterList(\n",
       "      (0): Object of type: SAGEConv\n",
       "      (1): Object of type: SAGEConv\n",
       "      (2): Object of type: SAGEConv\n",
       "      (3): Object of type: SAGEConv\n",
       "    (0): SAGEConv(55, 128, aggr=mean)\n",
       "    (1): SAGEConv(128, 128, aggr=mean)\n",
       "    (2): SAGEConv(128, 128, aggr=mean)\n",
       "    (3): SAGEConv(128, 2, aggr=mean)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SAGE(in_dim=num_features, out_dim=OUT_DIM, **paras).to(DEVICE)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5110"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.x.shape[0]//batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 2,  ..., 1, 2, 2], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 0/100; Batch: 866/5110; Loss: nan:   0%|          | 0/100 [00:08<?, ?it/s]       \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 37\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_all, loss_valid_all\n\u001b[1;32m     35\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mparas[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m], weight_decay\u001b[38;5;241m=\u001b[39mparas[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml2\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 37\u001b[0m loss_all, loss_valid_all \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch_num\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 12\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(batches, model, optimizer, epoch_num)\u001b[0m\n\u001b[1;32m     10\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     11\u001b[0m running_valid_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 12\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/smcs/lib/python3.12/site-packages/torch_geometric/loader/base.py:39\u001b[0m, in \u001b[0;36mDataLoaderIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform_fn(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/smcs/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/anaconda3/envs/smcs/lib/python3.12/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/anaconda3/envs/smcs/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/smcs/lib/python3.12/site-packages/torch_geometric/loader/node_loader.py:147\u001b[0m, in \u001b[0;36mNodeLoader.collate_fn\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Samples a subgraph from a batch of input nodes.\"\"\"\u001b[39;00m\n\u001b[1;32m    145\u001b[0m input_data: NodeSamplerInput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_data[index]\n\u001b[0;32m--> 147\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_sampler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_from_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_per_worker:  \u001b[38;5;66;03m# Execute `filter_fn` in the worker process\u001b[39;00m\n\u001b[1;32m    150\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilter_fn(out)\n",
      "File \u001b[0;32m~/anaconda3/envs/smcs/lib/python3.12/site-packages/torch_geometric/sampler/neighbor_sampler.py:322\u001b[0m, in \u001b[0;36mNeighborSampler.sample_from_nodes\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msample_from_nodes\u001b[39m(\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    320\u001b[0m     inputs: NodeSamplerInput,\n\u001b[1;32m    321\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[SamplerOutput, HeteroSamplerOutput]:\n\u001b[0;32m--> 322\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mnode_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubgraph_type \u001b[38;5;241m==\u001b[39m SubgraphType\u001b[38;5;241m.\u001b[39mbidirectional:\n\u001b[1;32m    324\u001b[0m         out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mto_bidirectional()\n",
      "File \u001b[0;32m~/anaconda3/envs/smcs/lib/python3.12/site-packages/torch_geometric/sampler/neighbor_sampler.py:542\u001b[0m, in \u001b[0;36mnode_sample\u001b[0;34m(inputs, sample_fn)\u001b[0m\n\u001b[1;32m    539\u001b[0m     seed \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mnode\n\u001b[1;32m    540\u001b[0m     seed_time \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mtime\n\u001b[0;32m--> 542\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43msample_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed_time\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m out\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;241m=\u001b[39m (inputs\u001b[38;5;241m.\u001b[39minput_id, inputs\u001b[38;5;241m.\u001b[39mtime)\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/envs/smcs/lib/python3.12/site-packages/torch_geometric/sampler/neighbor_sampler.py:459\u001b[0m, in \u001b[0;36mNeighborSampler._sample\u001b[0;34m(self, seed, seed_time, **kwargs)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Homogeneous sampling:\u001b[39;00m\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;66;03m# TODO Support induced subgraph sampling in `pyg-lib`.\u001b[39;00m\n\u001b[1;32m    452\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (torch_geometric\u001b[38;5;241m.\u001b[39mtyping\u001b[38;5;241m.\u001b[39mWITH_PYG_LIB\n\u001b[1;32m    453\u001b[0m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubgraph_type \u001b[38;5;241m!=\u001b[39m SubgraphType\u001b[38;5;241m.\u001b[39minduced):\n\u001b[1;32m    455\u001b[0m         args \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    456\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolptr,\n\u001b[1;32m    457\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrow,\n\u001b[1;32m    458\u001b[0m             \u001b[38;5;66;03m# TODO (matthias) `seed` should inherit dtype from `colptr`\u001b[39;00m\n\u001b[0;32m--> 459\u001b[0m             \u001b[43mseed\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolptr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    460\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_neighbors\u001b[38;5;241m.\u001b[39mget_mapped_values(),\n\u001b[1;32m    461\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_time,\n\u001b[1;32m    462\u001b[0m         )\n\u001b[1;32m    463\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch_geometric\u001b[38;5;241m.\u001b[39mtyping\u001b[38;5;241m.\u001b[39mWITH_EDGE_TIME_NEIGHBOR_SAMPLE:\n\u001b[1;32m    464\u001b[0m             args \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medge_time, )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(batches, model, optimizer, epoch_num=1):\n",
    "    loss_all = []\n",
    "    loss_valid_all = []\n",
    "\n",
    "    model.train()\n",
    "    iterator = tqdm(range(epoch_num), desc=\"\")\n",
    "    for epoch in iterator:\n",
    "        running_loss = 0\n",
    "        running_valid_loss = 0\n",
    "        for idx, batch in enumerate(batches):\n",
    "            optimizer.zero_grad()\n",
    "            out = model(batch.x, batch.edge_index)\n",
    "\n",
    "            loss = F.nll_loss(out[batch.train_mask], batch.y[batch.train_mask])\n",
    "            running_loss += loss.item()    \n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_valid = F.nll_loss(out[batch.val_mask], batch.y[batch.val_mask])\n",
    "            running_valid_loss += loss_valid.item()    \n",
    "\n",
    "            iterator.set_description(f\"Epoch: {epoch}/{epoch_num}; Batch: {idx}/{data.x.shape[0]//batch_size}; Loss: {running_loss/(idx+1):0.4f}\")\n",
    "\n",
    "        # @TODO: add validation round to monitor performance\n",
    "        loss_all += [running_loss/(data.x.shape[0]//batch_size)]\n",
    "        loss_valid_all += [running_valid_loss/(data.x.shape[0]//batch_size)]\n",
    "\n",
    "        iterator.set_description(f\"Epoch: {epoch}/{epoch_num}; Batch: {idx}; Loss={loss_all[-1]:.4f}; Loss-Validation={loss_valid_all[-1]:.4f}\")\n",
    "\n",
    "    return loss_all, loss_valid_all\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=paras[\"lr\"], weight_decay=paras[\"l2\"])\n",
    "\n",
    "loss_all, loss_valid_all = train(loader, model, optimizer, epoch_num=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x736ac8136ed0>]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_all)\n",
    "plt.plot(loss_valid_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "52it [00:00, 147.69it/s]                        \n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.explain.metric import groundtruth_metrics\n",
    "\n",
    "avg_scores = []\n",
    "model.eval()\n",
    "for batch in tqdm(loader, total=dataset.x.shape[0]//batch_size):\n",
    "    pred = model(batch.x, batch.edge_index).argmax(dim=1)\n",
    "    scores = groundtruth_metrics(\n",
    "        pred_mask=pred[batch.test_mask],\n",
    "        target_mask=batch.y[batch.test_mask],\n",
    "        threshold=0.5,\n",
    "        metrics=[\"accuracy\", \"precision\", \"recall\", \"f1_score\"]\n",
    "    )\n",
    "    avg_scores += [scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99704236, 0.99704236, 1.        , 0.99851812])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.asarray(avg_scores).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.explain.metric import groundtruth_metrics\n",
    "\n",
    "# model.eval()\n",
    "# pred = model(train_data).argmax(dim=1)\n",
    "\n",
    "# groundtruth_metrics(\n",
    "#     pred_mask=pred[train_data.test_mask],\n",
    "#     target_mask=train_data.y[train_data.test_mask],\n",
    "#     threshold=0.5,\n",
    "#     metrics=[\"accuracy\", \"precision\", \"recall\", \"f1_score\"]\n",
    "# )\n",
    "\n",
    "# # correct = (pred[train_data.test_mask] == train_data.y[train_data.test_mask]).sum()\n",
    "# # acc = int(correct) / int(train_data.test_mask.sum())\n",
    "# # print(f'Accuracy: {acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smcs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
